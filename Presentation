---
title: 'Introduction to Statistical Decision Theory'
 # subtitle: ''
author: "Arthur Small"
date:   "SYS 6014 Decision Analysis, Spring 2020"
output:
 #  beamer_presentation:
 # #   theme: "metropolis"
 #    theme: "AnnArbor"
 #    colortheme: "dolphin"
 #    fonttheme: "structuresmallcapsserif"
 #    toc: true
 #    #toc_depth: 3
 #    slide_level: 3
 #    fig_width: 3.5
 #    fig_height: 3
 #    fig_caption: true
    
   html_document:
    toc: true
   
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r make_beamer_slides, include=FALSE, eval= FALSE}
library(rmarkdown)
# See documentation at: https://rdrr.io/cran/rmarkdown/man/beamer_presentation.html
# and at: https://bookdown.org/yihui/rmarkdown/beamer-presentation.html
# and at: https://rdrr.io/cran/rmarkdown/man/render.html
render("", beamer_presentation(
  toc = FALSE,
  slide_level = NULL,
  number_sections = FALSE,
  incremental = FALSE,
  fig_width = 10,
  fig_height = 7,
  fig_crop = TRUE,
  fig_caption = TRUE,
  dev = "pdf",
  df_print = "default",
  theme = "default",
  colortheme = "default",
  fonttheme = "default",
  highlight = "default",
  template = "default",
  keep_tex = FALSE,
  keep_md = FALSE,
  latex_engine = "pdflatex",
  citation_package = c("none", "natbib", "biblatex"),
  self_contained = TRUE,
  includes = NULL,
  md_extensions = NULL,
  pandoc_args = NULL
)
```


## Data-driven decision-making


### Data-driven decision-making: Motivations

Humans make billions of decisions every day. Many of these decisions are not optimal. Many are based on unexamined replication of whatever procedures were used historically. Sub-optimal decisions create waste. 

Explosion of access to data, analytic tools, & computing power opens new opportunities for decisions to be more data driven.

### The general form of the problems weâ€™ll take up

- There is a decision-maker who must choose one option from a menu of options.
- The decision-maker has objectives. 
    * These objectives can be quantified in the form of an *objective function* (equivalently, a *loss function*).
- The payoffs to different choices depend on the values of certain *state variables* or unobserved *parameters*. The payoff function expresses the costs and benefits the result from the decision-maker's chosen action.
  * In some applications, it makes sense to model the payoffs as depending on the realized value of a random state variable.
  * In other applications, it makes sense to model the payoff's as depending on the value of the unobserved parameter.

 - The decision-maker is in general *uncertain* about the values of the relevant state variables or parameters. In general, we will represent the information the decision-maker has in the form of *probability distributions* over the relevant state variables or parameters.
    
- In most applications we will consider, tools are available to reduce these uncertainties. Depending on the application, the tool might be derived from a statistical model, a machine learning model, or a forecasting system based on a physical model. We will refer to these informational tools collectively as *predictive models*.


### Building decision models

The decision problem:

Who is the decision-maker?

What decision does this agent confront?

What is the set of options (or potential actions) from which this decision-maker chooses? 

What are the stakes of the decision? What real costs and benefits are realized from making better vs. poorer decisions?

The predictive tool: 

What information does your chosen predictive tool provide?
How will the decision maker use the information generated by this tool to make better decisions?
 
## Formalism for statistical decision models

### Actions

A decision-maker must choose from exactly one action $a$ from an *action space* $\mathbb{A}$: $a \in \mathbb{A}$

#### Example

 - The decsion-maker is a doctor. 
 - $\mathbb{A} = \{$"give medication", "don't give medication"$\}$.

In some applications, each menu option $a$ will correspond to a bundle or vector of distinct actions. In these cases, the action space $\mathbb{A}$ will include an exhaustive list of all such bundles or vectors.

### States

In our nomenclature, *states* refer to *observable data* about relevant conditions. 

A state $x$ will correspond to a single point in a *state space*. 

A state space $\mathbb{X}$ describes the set of all possible values that $x$ might take:  $x \in \mathbb{X}$.

#### Example

A test can be performed to determine whether a patient has a certain medical condition. 

Let $x$ denote the test result, which may be positive ($x =$"Y") or negative ($x =$"N").

The state space is the set of all possible outcomes for this test: 
$x \in \mathbb{X} = \{$"N", "Y"$\}$.

#### Note
Notationally, it will often be more convenient to use numeric values for states, e.g., 
$X = \{0,1\}$, where $x=1$ corresponds to a positive test.

### Random states

Before observing the actual realized value $x$ of the system's state, the system's true state is unknown. 

In a typical application, we will nonetheless have some idea about the likelihood that the system's state $x$ will attain each of the possible values in the state space $\mathbb{X}$. 

Formally, our beliefs about the system's state can be represented by a *probability distribution over the state space* $\mathbb{X}$. 

#### Example

For $x \in \mathbb{X} = \{0,1\}$, let $f(1) = \Pr\{x = 1\}$ and 
$f(0) = 1-f(1) = \Pr\{x = 0\}$. 

### Random variables

Prior to knowing the realized value of the system's state, its true value is an uncertain *random variable*. 

By convention, we will use capital letters to refer to random variables, and lower case letters to refer to corresponding realized values.

Here, $X$ denotes a random variable that takes values from on the state space $\mathbb{X}$, and $x$ denotes its realized value in $\mathbb{X}$. 

Let $f(x | \theta)$ denote the 



### Random states

For $x \in \mathbb{X}$, let $f(x)$ define a probability distribution over $\mathbb{X}$. 

Let $B \subset \mathbb{X}$. If $\mathbb{X}$ is discrete, then 

$$ \Pr\{x \in B\} = \sum_{x \in B} f(x)$$
If $\mathbb{X}$ is continuous, then 

$$ \Pr\{x \in B\} = \int_{x \in B} f(x)$$


More generally, if $x$ can take any of a finite number of values $1, 2, \ldots, N$, then a probability distribution over the state space $\mathbb{X} = \{1, \ldots, N\}$ can be represented by a vector $\theta = <\theta_1, \theta_2, \ldots, \theta_N>$, where $\theta_n = \Pr\{x = n\}$. 



Since $\theta$ represents a probability distribution, we must have that $\theta_n \geq 0$ for all $n$, and $\sum \theta_n = 1$.



#### Example







### Parameters

A *parameter* is a variable that describes the condition of the system, that is *not* directly observable. An *unobserved* parameter $\theta$ takes values on a *parameter space* $\mathbb{\Theta}$: $\theta \in \mathbb{\Theta}$.

### Payoffs

After choosing an action, the decision-maker realizes a *payoff*. This payoff depends on the chosen action $a$. Depending on the situation being modeled, it may make sense to express payoffs either in terms of the realized value of the system's state, or on the value of the unobserved parameters.

#### Payoffs as a function of action and state

Let $u(a,x)$ denote the payoffs from a given action $a$ and state $x$.

$$ E[u(a, X) |\theta] = \int_\mathbb{X} p(x) u(a,x) dx $$

Then define the expected payoff $U(a,\theta)$ as a function of $\theta$ in these terms:

$$ U(a,\theta) = E[u(a, X) |\theta] = \int_\mathbb{X} p(x) u(a,x) dx $$

More generally in terms of utility:

$$ u()

## Statistical decision theory



### Formalism for statistical decision models



The payoff to a decision depends on the value of some unobserved parameter $\theta$, which could be a vector.
We have some system for generating a probability distribution $\pi(\theta)$ over $\theta$.
In Bayesian approaches, the probability distribution $\pi(\theta)$ used is the posterior distribution of $\theta$ given the observed data: $\pi(\theta | y)$.
Other approaches exist for creating probability distributions over states

## 

## Slide With Image Left

::: columns

:::: column
left

```{r your-chunk-name, echo=FALSE, fig.cap="your-caption-name"}
#The figure will appear on the right side of the slide...
```

::::

:::: column
right

```{r your-chunk-name2, echo=FALSE, fig.cap="your-caption-name"}
#The figure will appear on the right side of the slide...
```
::::

:::

# Additional notes

Background: This course centers on a semester-long project to build a working algorithmic decision tool. As used here, the term algorithmic decision tool means a computational system that empowers a user to make data-driven, near-optimal decisions in a specific domain area.

In the broadest terms, you can think of a decision tool as having two components, or modules:

A prediction component that generates information (possibly imperfect) about the state of the world; and
An optimization component that identifies the best action to take, given the information provided by your prediction tool.
In the first two lectures, we've introduced the basic concepts of statistical decision theory - a rigorous framework for taking optimal decisions under conditions of uncertainty. In the context of a bare-bones simple model, we've addressed how to formalize a decision problem in terms of uncertain random variables, the menu of possible actions, the potential payoffs from choosing alternative actions, and the decision-maker's ultimate objectives. We analyzed this model to derive optimal decision rules: rules for choosing actions optimally, given the decision-maker's beliefs, possible actions, payoffs, and ultimate objectives.  We've considered how improvements in information can lead to better decisions: with better information, the decision-maker is more likely (though not guaranteed) to opt for actions that improve her results. We've derived formal expressions for the expected value of information, defined as the improvement in the decision-maker's expected payoffs when the she can make choices on the basis of better information.

In this assignment, you are asked to think about how this framework and these concepts might apply in some real-world application. You are asked to consider some decision problem in which there are real stakes of some kind, and in which a decision-maker could benefit from access to better information. You are asked to describe this decision problem, in outline sketch; and to describe how some information source might help the decision-maker to make better choices.

The goal here is not (yet) to articulate a formal model. Rather, the goal is to begin to give some initial thoughts towards selecting your project topic.

Relation to your own research: If you are working on a research project that involves analyzing data to extract summary information, you are invited to ask yourself: Who will actually use this information? What will they use it for? How much value does could this information provide?

Many people think that if they provide "better" information about some domain area, then better outcomes inevitably will flow forth. But actually, this is not necessarily true. What you are asked to do here is to think rigorously about exactly who will use the information you are providing, how they will use it, and how much value will be realized by empowering them to make better decisions. 

If you are working hard to create some information tool, but cannot think of any application in which someone might actually use the information output from this tool make better decisions, you might well pause and ask yourself: Why am I doing this? If no one will ever use the information you are generating, then why are you producing it?

That question is not meant to be sarcastic, or dismissive. It is meant to press you to think hard about how you are using your scarce time and years on this Earth, and to nudge you in directions that create value.

If you are not currently working in a research group to create some predictive or information-productive tool: Think about some work you have done in the past, some predictive tool you are familiar with, or some informative tools used in your area of professional practice. Think about some way this information could be used be a decision-maker to make better decisions.

If you are really stuck and can't think of anything, come see me, and we'll try to find a good topic together. But first, really try to think of a topic on your own.

 

The assignment: In one page, or at most two, articulate a succinct description of a decision problem along the above lines. Make sure your description addresses the following questions:

The decision problem:

Who is the decision-maker?

What decision does this agent confront?

What is the set of options (or potential actions) from which this decision-maker chooses? 

What are the stakes of the decision? What real costs and benefits are realized from making better vs. poorer decisions?

The predictive tool: 

What information does your chosen predictive tool provide?
How will the decision maker use the information generated by this tool to make better decisions?
 

If you are a bit more ambitious, and still have space, you might address some of these questions:

In what units are payoffs measured?

How, in general terms, are payoffs calculated?

What are the uncertain state variables that influence the value of payoffs?

What is the range of possible values of these variables?

What analytic technique(s) will you use to estimate the values of these uncertain state variables?

What data will you use in this estimation? Are you sure you can gain access to these data?

In what programming language and platform will you perform your coding?
